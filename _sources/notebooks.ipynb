{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](logo.jpeg)\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "Continuous advancements in Unmanned Aerial Vehicle (UAV) technology have broadened its applications in agriculture. These innovations play a crucial role in fostering sustainable solutions and influencing policies and decisions in agriculture. However, the regulatory framework for UAV flights and the development of standardized protocols for precise data capture are continuously evolving. It is imperative to uphold accurate data quality for synergizing multiyear data and other spectral sensors (satellites, drones, lab sensors. To maintain high standards, some essential steps were proposed. \n",
    "\n",
    "# 2. Pre planning\n",
    "## 2.1. Flight planning\n",
    "* To carry successful drone surveys, a strategic flight planning is required using a standard flight planning software. Coordinate with the project representative to establish suitable flight parameters, including spatial resolution, date, and additional ancillary measurements. \n",
    "\n",
    "* Ensure the survey area is not within classfied airspace.\n",
    "\n",
    "* List the equipment required for the survey. \n",
    "\n",
    "* Select clearly identifiable ground control point (GCP) locations within the survey area, essential for referencing UAV products.\n",
    "## 2.2. Weather forecasting\n",
    "Verify the weather forecast before initiating the survey.\n",
    "Increasing availability atmosphere data from multiple satellites enables to predict accurate weather prediction for drone campaigns. \n",
    "\n",
    "Accessing weather information from ECMWF forecasts and Meteosat imagery allows the user to view up to two synchronised loops of the products. \n",
    "\n",
    "If possible, obtain local/in-situ weather conditions (cloud cover, wind etc.) from the site person. \n",
    "## 2.3. Site and risk assessment and permissions\n",
    "The pilot should identify the site using given coordinates in Google earth Maps or ArcGIS. \n",
    "\n",
    "Identify geographical features (big trees, bird conservation parks, tall building, electric polls/wires) around the survey area which might affect the data (electromagnetic interference) and flight planning.   \n",
    "\n",
    "Identify possible hazards within the survey area. \n",
    "\n",
    "The restrictions (permanent and temporary) over the site should be checked. \n",
    "\n",
    "To ensure lawful and ethical operations, the site permission should be obtained from the project representative/ site manager.  \n",
    "## 2.4. Flight survey time \n",
    "\n",
    "* Record the site conditions in the logbook before initiating the drone flight. \n",
    "\n",
    "* Check the GPS/GNSS quality, ensuring a minimum of 5 satellites are available. \n",
    "\n",
    "* Place the GCP targets in pre-defined locations. \n",
    "\n",
    "* Ensure sensors lens is clean if not clean with a lens tissue. \n",
    "\n",
    "* Turn ON instruments, especially the spectral camera, 15 minutes before collecting actual measurements. \n",
    "\n",
    "* Ensure that a clean calibration target should be used for the calibration. \n",
    "\n",
    "* It is advisable to record the calibration target before after the survey. If the survey area is big, additional measurements are required. \n",
    "\n",
    "* Record essential parameters in metadata sheet (Table 1) and logbook. \n",
    "\n",
    "## 2.5. Ancillary measurements to support UAV acquisitions. \n",
    "Calculating accurate surface reflectance values are essential in various applications and to synergies with other data. To support this, additional measurements can be conducted. \n",
    "\n",
    "**Field spectroradiometer**\n",
    "\n",
    "* Simultaneously with the drone flight, ground spectral measurements can be acquired using a spectroradiometer to align with drone spectral data. \n",
    "\n",
    "* Downwelling solar radiation can be captured with a spectroradiometer, utilizing a sensor fiber attached to a cosine receptor and positioned upward with a tripod. \n",
    "\n",
    "**Sun photometer** for measuring aerosol optical thickness.\n",
    "\n",
    "# 3. Data management\n",
    "After the drone flight, cross checking is performed to ensure detailed metadata is recorded, and data is stored in an appropriately. Effective data management is crucial for subsequent analysis. \n",
    "\n",
    "Visual evaluation of images is necessary to identify undesirable aspects such as blurry images (RGB), illumination variations, and naming issues. \n",
    "\n",
    "# 4. Data processing piepleines\n",
    "\n",
    "The radiometric response of optical sensors/ remote sensing imagery play critical role in obtaining quantitative spectral infromation. Typically, the data from the spectral sensors can be delivered as digital numbers, radiance, and reflectance. \n",
    "\n",
    "* Digital numbers(DN) The amount of reflected light energy measured by the sensor recorded in the form of a binary integers which is not considered as qunatitative value thus not scientifc value. The range of binary integers depend on the radiometric resolution of the sensor. For example A sensor with 8 bits (rediometric resolution) records the data from 0 to 255, while 16 bits sensor records values from 0 to 65536.\n",
    "Radiometric resolution indciates the sensor sensitivity to detect minor energy differences. High resolution sensors has higher sensitivity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1. Converting Digital numbers to Radiance\n",
    "\n",
    "Radiance The DN converted to radiance using the a gain and offset values per each band, this process also called as radiometric calibration. The gain and offset values generally supplied from teh sensor manufactrer, if not the values can be retrieved using an integrating sphere. The radaince units are watts/m2 steradian nm.\n",
    "\n",
    "$$\n",
    "L_{band} = DN * Gain_{band} + Offset_{band}\n",
    "$$\n",
    "\n",
    "where: \n",
    "\n",
    "* L_band = spectral radaince c(watts/(m2*steradian nm)\n",
    "* DN = Digital numbers\n",
    "* Gain =  Slope of the spectral band\n",
    "* Offset = Intercept of the spectral band\n",
    "\n",
    "\n",
    "# 4.2. Radiance to Reflectance\n",
    "\n",
    "The portional of the light reflected from the object to the sensors. The reflectance measured in the range of 0-100% which depend on the properties of the reflected surface. Since the radiance values infleunced by various components (atmospheric and aerosol profile, and geometric factors) their interactions with radition, conversion into surface relfectance is essential to retrive phenological infromation.\n",
    "Generally three methods are followed these effects.\n",
    "\n",
    "* Empirical Line\n",
    "* Atmospheric Radiative transfer model (RTM)\n",
    "* Hybrid method\n",
    "\n",
    "Empirical appraoches are widely used because of ease in implementation and repeatable under constant illumination conditions based on linear regression between reference panels and drone radiance values.\n",
    "Reading the raw multispectral images from the drone and and calibrating them into reflectance maps and stitiching the phtos can be done using different photorammetry softwares (Pix4D, Agrisoft, ArcGIS Drone2map).\n",
    "In case of multispectral images stadard reference panels (white and dark) are used to determine the scale factor which later applied over the image to convert into reflectance cube. The above softwares automatically extract reference panel information from by finding the QR code within an image. \n",
    "\n",
    "# 4.3. Deriving vegetation indices\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'float32',\n",
       " 'nodata': -32767.0,\n",
       " 'width': 3529,\n",
       " 'height': 3432,\n",
       " 'count': 6,\n",
       " 'crs': CRS.from_epsg(7853),\n",
       " 'transform': Affine(0.020399847655346234, 0.0, 433027.87620212696,\n",
       "        0.0, -0.020401199596840672, 6378518.849946602)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "image_array = rasterio.open('data/Multispec_30m.tif')\n",
    "image_array.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1233249\\AppData\\Local\\Temp\\ipykernel_31296\\866925832.py:22: RuntimeWarning: invalid value encountered in sqrt\n",
      "  MSAVI2 = 0.5 * (2 * nir.astype(float) + 1 - np.sqrt(2 * nir.astype(float) + 1) * 2 - 8*(nir.astype(float) - red.astype(float)))\n",
      "C:\\Users\\a1233249\\AppData\\Local\\Temp\\ipykernel_31296\\866925832.py:25: RuntimeWarning: divide by zero encountered in divide\n",
      "  ARVI = (nir.astype(float) + blue.astype(float))/(nir.astype(float) - blue.astype(float))\n"
     ]
    }
   ],
   "source": [
    "# Spectral Bands\n",
    "\n",
    "green = image_array.read(1)\n",
    "blue = image_array.read(2)\n",
    "red = image_array.read(3)\n",
    "rededge = image_array.read(3)\n",
    "nir = image_array.read(3)\n",
    "panchromatic = image_array.read(3)\n",
    "\n",
    "#NDVI - Normalized Vegetation Index\n",
    "NDVI = (nir.astype(float) - red.astype(float)) / (nir + red)\n",
    "\n",
    "#RVI - Simple Ratio Vegetation Index\n",
    "RVI = nir.astype(float)/red.astype(float)\n",
    "\n",
    "#SAVI - Soil Adjusted Vegetation Index\n",
    "L= 0.5\n",
    "SAVI = (nir.astype(float) - red.astype(float))/(nir.astype(float) + red.astype(float) + L)\n",
    "\n",
    "# MSAVI2 - Modified Secondary Soil Adjusted Vegetation Index\n",
    "\n",
    "MSAVI2 = 0.5 * (2 * nir.astype(float) + 1 - np.sqrt(2 * nir.astype(float) + 1) * 2 - 8*(nir.astype(float) - red.astype(float)))\n",
    "                                                               \n",
    "# ARVI - Atmospheric Resistant Vegetation Index\n",
    "ARVI = (nir.astype(float) + blue.astype(float))/(nir.astype(float) - blue.astype(float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot more that you can do with outputs (such as including interactive outputs)\n",
    "with your book. For more information about this, see [the Jupyter Book documentation](https://jupyterbook.org)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
